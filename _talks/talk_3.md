---
layout: post
title: \[Conference\] Talks at ICSE 2023.
date: 2023-05-19 00:00:00
inline: false
related_posts: false
---

|:---: | :--- |
| **Title** | DeepVD: Toward Class-Separation Features for Neural Network Vulnerability Detection|
| **Venue** | Melbourne, Australia. |
| **Abstract** | *The advances of machine learning (ML) including deep learning (DL) have enabled several approaches to implicitly learn vulnerable code patterns to automatically detect software vulnerabilities. A recent study showed that despite successes, the existing ML/DL-based vulnerability detection (VD) models are limited in the ability to distinguish between the two classes of vulnerability and benign code. We propose DeepVD, a graph-based neural network VD model that emphasizes on class-separation features between vulnerability and benign code. DeepVD leverages three types of class-separation features at different levels of abstraction: statement types (similar to Part- of-Speech tagging), Post-Dominator Tree (covering regular flows of execution), and Exception Flow Graph (covering the exception and error-handling flows). We conducted several experiments to evaluate DeepVD in a real-world vulnerability dataset of 303 projects with 13,130 vulnerable methods. Our results show that DeepVD relatively improves over the state-of-the-art ML/DL- based VD approaches 13%–29.6% in precision, 15.6%–28.9% in recall, and 16.4%–25.8% in F-score. Our ablation study confirms that our designed features and components help DEEPVD achieve high class-separability for vulnerability and benign code.* |
| **Links** | [[slides]](https://aashishyadavally.github.io/assets/pdf/slides-icse2023-(2).pdf) [[video]](https://www.youtube.com/watch?v=HMlf9rxvWyc&list=PLn0nrSd4xjjapJtUftrtI1oxP6Z16BUec&index=44&t=14m12s)|

---

|:---: | :--- |
| **Title** | (Partial) Program Dependence Learning|
| **Venue** | Melbourne, Australia. |
| **Abstract** | *Code fragments from developer forums often migrate to applications due to the code reuse practice. Owing to the incomplete nature of such programs, analyzing them to early determine the presence of potential vulnerabilities is challenging. In this work, we introduce NeuralPDA, a neural network-based program dependence analysis tool for both complete and partial programs. Our tool efficiently incorporates intra-statement and inter-statement contextual features into statement representations, thereby modeling program dependence analysis as a statement-pair dependence decoding task. In the empirical evaluation, we report that NeuralPDA predicts the CFG and PDG edges in complete Java and C/C++ code with combined F-scores of 94.29% and 92.46%, respectively. The F-score values for partial Java and C/C++ code range from 94.29%–97.17% and 92.46%–96.01%, respectively. We also test the usefulness of the PDGs predicted by NeuralPDA (i.e., PDG*) on the downstream task of method-level vulnerability detection. We discover that the performance of the vulnerability detection tool utilizing PDG* is only 1.1% less than that utilizing the PDGs generated by a program analysis tool. We also report the detection of 14 real-world vulnerable code snippets from StackOverflow by a machine learning-based vulnerability detection tool that employs the PDGs predicted by NeuralPDA for these code snippets.* |
| **Links** | [[slides]](https://aashishyadavally.github.io/assets/pdf/slides-icse2023-(1).pdf)|
